# -*- coding: utf-8 -*-
"""particle_life_data_extractor-new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16XMZCQtAUXp8_ZX2UvflEJtOf3ldqch1
"""

from google.colab import files
uploaded = files.upload()  # pick your JSON file
CONFIG_PATH = next(iter(uploaded))  # use the uploaded filename
print("Using:", CONFIG_PATH)

#!pip install playwright
#!playwright install-deps chromium
#!python -m playwright install chromium

import json, pandas as pd, math
from playwright.async_api import async_playwright

URL = "https://basaga.org/basaga_files/partificial-life/index.html"
CONFIG_PATH = "config.json"
TIMEOUT_MS = 30000
NUM_SAMPLES = 1000
STEP_GAP = 1
CHUNK = 100

async def run_and_sample_progress(url, config_path, num_samples=1000, step_gap=1, timeout_ms=30000, chunk=100):
    cfg = json.load(open(config_path, "r", encoding="utf-8"))
    all_rows = []

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True, args=["--no-sandbox", "--disable-dev-shm-usage"])
        context = await browser.new_context()
        page = await context.new_page()

        await page.goto(url, wait_until="domcontentloaded")
        await page.wait_for_function("() => window.simAPI && typeof window.simAPI.start === 'function'", timeout=timeout_ms)

        await page.evaluate("cfg => window.simAPI.loadConfig(cfg)", cfg)
        await page.evaluate("() => { window.simAPI.reset(); window.simAPI.start(); }")

        batches = math.ceil(num_samples / chunk)
        for b in range(batches):
            take = min(chunk, num_samples - b*chunk)
            rows = await page.evaluate(
                """async ({n, gap}) => {
                    const out = [];
                    let target = (window.simAPI.getMetrics()?.step || 0);
                    for (let i = 0; i < n; i++) {
                        target += gap;
                        await window.simAPI.waitUntil(m => m.step >= target, { timeoutMs: 600000 });
                        const m = window.simAPI.getMetrics();
                        out.push([m.cluster, m.entropy, m.speed, m.change, m.cvi, m.step, performance.now()]);
                    }
                    return out;
                }""",
                {"n": take, "gap": step_gap}  # <-- pass as one object
            )
            all_rows.extend(rows)
            print(f"Collected {len(all_rows)} / {num_samples}")

        await browser.close()

    df = pd.DataFrame(all_rows, columns=["cluster","entropy","speed","change","cvi","step","t_ms"])
    df.to_csv("metrics_1000_samples.csv", index=False)
    print("Saved metrics_1000_samples.csv")
    return df

# Run it
df = await run_and_sample_progress(URL, CONFIG_PATH, NUM_SAMPLES, STEP_GAP, TIMEOUT_MS, CHUNK)
df.tail()

import matplotlib.pyplot as plt

data = df.copy()
cvi = data['cvi']
plt.figure(figsize=(8, 4.5))
plt.plot(cvi)  # no explicit colors/styles per your requirements
plt.title("Composite Volatility Index (CVI) â€” per sample")
plt.xlabel("Sample index")
plt.ylabel("CVI")
plt.tight_layout()

df.head(30)

import time

# 1) Pick a filename (timestamped so you don't overwrite previous runs)
fname = f"metrics_{int(time.time())}.csv"

# 2) Save your DataFrame
df.to_csv(fname, index=False)
print("Saved:", fname)

# 3) Trigger a download (Colab)
from google.colab import files
files.download(fname)